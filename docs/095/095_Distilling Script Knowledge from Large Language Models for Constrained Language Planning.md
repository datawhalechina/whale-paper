# 1. 背景
 在日常生活中，人们经常通过遵循目标导向脚本的逐步指导来规划他们的行动。以往的研究利用语言模型（LMs）来规划抽象目标的典型活动（例如“制作蛋糕”），但对于具有多方面约束的更具体目标的规划研究还不够。以往的工作主要集中在规划抽象目标的典型活动上，对于具有特定约束的目标的规划研究仍然不够。以往的方法主要集中在生成抽象目标的脚本知识，而缺乏对具体约束的规划能力。
# 2. 动机
鉴于以往方法在受限语言规划方面的不足，本文旨在评估和改进大型语言模型的受限语言规划能力，并从大型语言模型中提取数据集以训练专门的模型。实证研究发现，大型语言模型在规划时往往流畅但不忠实于约束。因此，本文采用过度生成然后过滤的方法来提高生成脚本的质量。通过使用这种方法，本文使用大型语言模型生成了一个用于受限语言规划的高质量脚本数据集CoScript。实验结果表明，当在CoScript上进行训练时，较小的模型（如T5）可以取得良好的性能，甚至超过大型语言模型的性能。

# 3. 方法
本文提出了一种使用LLMs生成特定目标并为这些目标进行规划的工作流程。在特定目标生成步骤中，使用InstructGPT将抽象目标与约束进行扩展。在脚本生成步骤中，使用InstructGPT根据特定目标和约束生成脚本。然而，LLMs往往不符合约束条件，因此本文提出了一种过度生成然后过滤的框架来提高生成质量。
# 4. 实验
本文使用InstructGPT与人机协同的方法生成具有约束的特定目标。针对每种约束类型，准备了示例，并提示InstructGPT根据示例生成特定目标。
## 4.1 数据集
作者从wikiHow中随机收集100个抽象目标（例如，“做一个蛋糕”），并对生成的具体目标及其脚本进行手动评估。
## 4.2 对比模型
- T0
- Flan-T5
- vanilla GPT-3
- Codex
- InstructGPT

## 4.3 实验结果
本文进行了人工评估，比较了他们的方法与其他指导调优方法和语言模型的表现。他们随机收集了100个来自wikiHow的抽象目标，并生成了特定目标和脚本。评估结果显示，与其他方法相比，他们的方法在生成脚本方面的准确性更高。他们还发现，从wikiHow中检索并不能得到期望的脚本。此外，他们评估了InstructGPT生成的特定目标的质量，并发现该模型在生成正确特定目标方面的准确性达到了98%。
# 5. 总结
本研究首次定义了受限语言规划任务，并提出了一种过度生成然后过滤的方法来改进大型语言模型在此任务上的表现，同时使用该方法提取了一个新的受限语言规划数据集CoScript，实验证明该方法显著提高了大型语言模型的受限语言规划能力，特别是在约束忠实度方面，此外，CoScript对于赋予较小的语言模型受限语言规划能力也非常有效。

[comment]: <> (# 6. 视频)

[comment]: <> ( [链接]&#40;TODO&#41;)